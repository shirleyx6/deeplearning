'''numpy'''

import numpy as np

N,D_in,H,D_out=3,2,2,1
x0=np.array([[-0.5,1],[0.2,-0.6],[0.,0.5]])
y0=np.array([[1],[0.2],[0.5]])

w1_0=np.array([[0.5,0],[-0.5,1]])
w2_0=np.array([[-0.5],[0.5]])

learning_rate=0.1
n_epoch=2

x=x0.copy()
y=y0.copy()
w1=w1_0.copy()
w2=w2_0.copy()

for t in range(n_epoch):
    h=x.dot(w1)
    h_relu=np.maximum(h,0)
    y_pred=h_relu.dot(w2)   
    
loss=np.square(y_pred-y).sum()/N

grad_y_pred=2.0*(y_pred-y)/N
grad_w2=h_relu.T.dot(grad_y_pred)
grad_h_relu=grad_y_pred.dot(w2.T)
grad_h=grad_h_relu.copy()
grad_h[h<0]=0
grad_w1=x.T.dot(grad_h)

w1-=learning_rate*grad_w1
w2-=learning_rate*grad_w2

print('===epoch',t,'loss',loss,'===')
print('out',y_pred)
print('w1_new',w1)
print('w2_new',w2,'\n')

'''tensorflow'''

import tensorflow as tf

dtype=tf.float32

x=tf.placeholder(dtype,shape=x0.shape)
y=tf.placeholder(dtype,shape=y0.shape)
w1=tf.Variable(w1_0,dtype=dtype)
w2=tf.Variable(w2_0,dtype=dtype)

h=tf.matmul(x,w1)
h_relu=tf.maximum(h,0)
y_pred=tf.matmul(h_relu,w2)

loss=tf.reduce_sum((y-y_pred)**2.0)/N

grad_w1,grad_w2=tf.gradients(loss,[w1,w2])

w1_new=w1.assign_sub(learning_rate*grad_w1)
w2_new=w2.assign_sub(learning_rate*grad_w2)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for t in range(n_epoch):
        loss_,y_pred_,w1_,w2_=sess.run([loss,y_pred,w1_new,w2_new],feed_dict={x:x0,y:y0})
        print(t,loss_,y_pred_,w1_,w2_)
        
